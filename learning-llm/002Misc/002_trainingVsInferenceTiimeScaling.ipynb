{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0146c876-40e9-48a3-b9c4-919b5f217c1f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51864c35-17c7-4554-b988-4819a3bb7a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58de6a6-339d-425b-b5ad-b7baabfce9ae",
   "metadata": {},
   "source": [
    "## 1. Asking an easy question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "434d14ad-2d1e-4ac3-8a9c-7ae603834ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\":\"user\", \"content\": \"You toss 2 coins. One of them is heads. What's the probability the other is tails? Answer with the probility only.\"}]\n",
    "\n",
    "#the correct answer to this question is 2/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd0ae0f3-853e-4751-9881-f192b3ee0290",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "1/2"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(model=\"gpt-5-nano\", messages= messages, reasoning_effort=\"minimal\")\n",
    "display(Markdown( response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6afc0f3-fd94-44ba-857b-633ef654bc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it gives 1/2 which is wrong answer. this is because we are using the smallest model and that too we have explicityly asked to keep the\n",
    "# reasoning effort minimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a71126b4-9d8d-464e-a37b-05b1f51b5e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "2/3"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# now lets increase the reasoning level and see if it shows difference in output or not\n",
    "\n",
    "response = openai.chat.completions.create(model=\"gpt-5-nano\", messages= messages, reasoning_effort=\"low\")\n",
    "display(Markdown( response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2aedfd8a-a6af-4ee4-b97c-7b06141da142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# thus it gives the correct answer on increasing the reasoning_effort from minimal to low. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ad22ba7-ac70-4a85-aae6-7e7c77e57b5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "2/3"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## another way of increasing the result accuracy by increasing a more-powerful model all-together. thus lets use gpt-5-mini\n",
    "## instead of \"gpt-5-nano\" . note that  the gpt-5-mini comes up with the correct answer even after using the reason-effort-minimal \n",
    "## which was not the case gpt-5-nano\n",
    "\n",
    "response = openai.chat.completions.create(model=\"gpt-5-mini\", messages= messages, reasoning_effort=\"minimal\")\n",
    "display(Markdown( response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef080a91-02ae-44dd-b993-029434eea76d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "1/2."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# note that the llama3.2 comes up with wrong answer even after passing reasoning_effort=high\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
    "ollama = OpenAI(base_url = OLLAMA_BASE_URL, api_key= \"ollama\")\n",
    "response = ollama.chat.completions.create(model=\"llama3.2\", messages= messages, reasoning_effort=\"high\")\n",
    "display(Markdown( response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b1d9c9-168f-4353-af0a-817fec777981",
   "metadata": {},
   "source": [
    "## 2. asking a hard question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fd09a84-50ca-4653-8b0f-ae48e00d33a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hardproblem = \"\"\"\n",
    "On a bookshelf, two volumes of Pushkin stand side by side: the first and the second.\n",
    "The pages of each volume together have a thickness of 2 cm, and each cover is 2mm thick.\n",
    "A worm gnawed (perpendicular to the pages) from the first page of the first volume to the last page of teh second volume.\n",
    "What distance did it gnaw through?\n",
    "\"\"\"\n",
    "\n",
    "hard_puzzle =[{\"role\":\"user\", \"content\": hardproblem}]\n",
    "#the correct answer is 4mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cda02f07-1346-438e-9eb8-f8337d62ca6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Interpret the setup carefully:\n",
       "\n",
       "- Each volume has total page thickness 2 cm.\n",
       "- Each cover (front and back) is 2 mm thick.\n",
       "- The worm starts at the first page of the first volume and ends at the last page of the second volume, gnawing perpendicularly through the stack of books on the shelf.\n",
       "\n",
       "Let’s lay out the arrangement from left to right:\n",
       "- Volume 1: cover (front) | pages (2 cm) | cover (back)\n",
       "- Space between volumes: they sit side by side, no gap assumed\n",
       "- Volume 2: cover (front) | pages (2 cm) | cover (back)\n",
       "\n",
       "When the worm goes from the first page of the first volume to the last page of the second volume, it traverses:\n",
       "- Through the remaining pages of Volume 1 (from its first page to the back cover)\n",
       "- Through the back cover of Volume 1\n",
       "- Through the front cover of Volume 2\n",
       "- Through the pages of Volume 2 up to its last page\n",
       "\n",
       "However, the worm is entering at the very first page of Volume 1 and exiting at the very last page of Volume 2, so the only parts it does NOT gnaw through are:\n",
       "- The front cover of Volume 1 (the worm starts at the first page, not beyond it)\n",
       "- The back cover of Volume 2 (the worm ends at the last page, not beyond it)\n",
       "\n",
       "Therefore, the gnawed distance equals the total thickness of both volumes minus the two boundary non-gnawed portions (the front of V1 and the back of V2).\n",
       "\n",
       "Compute:\n",
       "- Total pages thickness: 2 cm per volume × 2 volumes = 4 cm\n",
       "- Except the front cover of V1 (2 mm) and the back cover of V2 (2 mm): subtract 4 mm total.\n",
       "\n",
       "Convert units: 4 cm = 40 mm. Subtract 4 mm → 36 mm.\n",
       "\n",
       "Answer: 3.6 cm (36 mm)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#lets ask this to \"gpt-5-nano\" with reasoning_effort=\"minimal\"\n",
    "\n",
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(model=\"gpt-5-nano\", messages= hard_puzzle, reasoning_effort=\"minimal\")\n",
    "display(Markdown( response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d528bf5-3316-4459-b6e6-e7e2d3397838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "4 mm\n",
       "\n",
       "Reason: The worm starts at the first page of the first volume and ends at the last page of the second volume. The straight line perpendicular to the pages between the volumes passes only through the two covers that touch each other: the front cover of volume 1 and the back cover of volume 2. Each cover is 2 mm thick, so the total distance gnawed is 2 mm + 2 mm = 4 mm. The pages themselves are irrelevant to the path."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#lets ask this to \"gpt-5-nano\" with reasoning_effort=\"low\"\n",
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(model=\"gpt-5-nano\", messages= hard_puzzle, reasoning_effort=\"low\")\n",
    "display(Markdown( response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ece3dad5-9da0-41e3-9c1c-5713edfb9f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Answer: 2 cm.\n",
       "\n",
       "Explanation: When the two books stand in reading order on the shelf (first volume on the left, second on the right), the \"first page of the first volume\" is at the leftmost face of that book and the \"last page of the second volume\" is at the rightmost face of the second book. A worm gnawing straight through from the first page of the first to the last page of the second therefore passes only through the two stacks of pages (2 cm each) but misses the inner covers between the books. In fact the worm's straight-line path goes across the two inner pages only — a total of 2 cm."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#lets ask this to \"gpt-5-mini\" with reasoning_effort=\"minimal\"\n",
    "response = openai.chat.completions.create(model=\"gpt-5-mini\", messages= hard_puzzle, reasoning_effort=\"minimal\")\n",
    "display(Markdown( response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d790e5a8-9c2b-406f-a23e-5b3be746b7d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To solve this problem, we need to calculate the total distance the worm traveled.\n",
       "\n",
       "The volume's thickness consists of two parts: the thickness of the pages and the thickness of the covers.\n",
       "\n",
       "Let's start with the pages:\n",
       "The first volume has x pages and the second volume has y pages. Together they form 2 volumes.\n",
       "We're trying to determine how the numbers x and y look in terms of overall distances.\n",
       "Each page is \"thin,\" so let d be the distance from one end of one page of the first volume to the other (the total pages thick), that's  2x = d , because we know the total thickness of both volumes was . We already know what this total thickness was: \n",
       "The overall thickness of two volumes is: 2cm + 2mm  =>   [ ] d + 22.4cm\n",
       "Substituting into that equation and simplifying it results in this equation:\n",
       "16x = 2.6 (cm)x \n",
       "Dividing both sides by 2 yields:\n",
       "8 x = 1.3 (cm)\n",
       "Now let's look at what happens to y; again we're trying to determine the total thickness of two volumes. So, let d be its distance and write it as: 2y +20(22.4) The same approach as before works as we can substitute that expression into the equation for total volume thickness:\n",
       "16y + 160 x .5 \n",
       "Substitute (1.3*8)x [1.04]x\n",
       "This simplifies to\n",
       "15x = 0.26 \n",
       "\n",
       " Dividing by both sides, d is\n",
       "   y\n",
       "The ratio in which the number of pages on each book appears to be roughly the same as our \"ratio\" for thickness:\n",
       "That's not true when we substitute: \n",
       "We know all that because when you can write things as the ratio \"a:x,\"\n",
       "this means that if we take a value, add (x*a),\n",
       "you're left with that original.\n",
       "Let's plug in 2.5\n",
       "Subtracting two times 1.04 gives us:\n",
       "0.06"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
    "ollama = OpenAI(base_url = OLLAMA_BASE_URL, api_key= \"ollama\")\n",
    "response = ollama.chat.completions.create(model=\"llama3.2\", messages= hard_puzzle, reasoning_effort=\"high\")\n",
    "display(Markdown( response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942a887d-627d-4003-a1fd-0ec7be9204c3",
   "metadata": {},
   "source": [
    "## 3. A spicy challenge to test the competitive spirit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ede3f9b2-c724-4b7f-a5b3-f9cb95b97e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "dilemma_prompt = \"\"\"\n",
    "You and a partner are contestants on a game show. You're each take to separate rooms and given a choice:\n",
    "Cooperate: Choose \"Share\" - if both of you choose this, you each win $1,000.\n",
    "Defect: Choose \"Steal\" - if one steals and the other shares, the stealer get $2,000 and the sharer gets nothing.\n",
    "If both steal, you both get nothing.\n",
    "Do you choose to Steal or Share? Pick one.\n",
    "\"\"\"\n",
    "\n",
    "dilemma = [\n",
    "    {\"role\":\"user\", \"content\": dilemma_prompt}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fa1889c-45a0-4287-bb7a-5b54b72f3590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I choose... Share.\n",
       "\n",
       "Given that there's a shared benefit to choosing \"Share\" (both of us getting $1,000 if we both make this choice), and no clear advantage to defecting in a situation where there are other players involved, I think cooperation is the best decision here. It may not guarantee the highest potential outcome for a purely individualistic perspective, but as part of a duo in a game show scenario, I'm inclined to prioritize mutual benefit over personal exploitation."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
    "ollama = OpenAI(base_url = OLLAMA_BASE_URL, api_key= \"ollama\")\n",
    "response = ollama.chat.completions.create(model=\"llama3.2\", messages= dilemma)\n",
    "display(Markdown( response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f208509-f35c-4b05-88b6-2bd0361f6450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I’ll choose Share."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#lets ask this to \"gpt-5-nano\" with reasoning_effort=\"minimal\"\n",
    "\n",
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(model=\"gpt-5-nano\", messages= dilemma, reasoning_effort=\"minimal\")\n",
    "display(Markdown( response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "275409ad-0e60-4292-b75c-ac396af6893f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Steal.\n",
       "\n",
       "Reason: It’s the dominant strategy in this setup. If the other person shares, stealing yields $2,000 vs $1,000. If the other person steals, stealing yields $0 just like sharing would, but you don’t lose anything by stealing. So stealing is the safest choice regardless of the other’s move."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#lets ask this to \"gpt-5-nano\" with reasoning_effort=\"low\"\n",
    "\n",
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(model=\"gpt-5-nano\", messages= dilemma, reasoning_effort=\"low\")\n",
    "display(Markdown( response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a46700b-76ad-438c-b74a-adfd7beeada2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I choose Share.\n",
       "\n",
       "Reason: If both of us choose Share we each get $1,000 — the best mutual outcome. Stealing risks both getting nothing if the other also steals, and while stealing can give $2,000 if the other cooperates, it can also leave me with $0. Choosing Share maximizes expected joint payoff and trusts the partner to do the same."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#lets ask this to \"gpt-5-mini\" with reasoning_effort=\"minimal\"\n",
    "response = openai.chat.completions.create(model=\"gpt-5-mini\", messages= dilemma, reasoning_effort=\"minimal\")\n",
    "display(Markdown( response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3693396d-0425-4681-a219-6f33ed5eec3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
