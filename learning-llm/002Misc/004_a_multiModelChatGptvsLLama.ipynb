{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65e14aa3-08a9-4f69-9b9b-6b59e931f5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d93bc62e-eb51-4543-ba5c-5a3e86afc335",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "openai = OpenAI()\n",
    "gpt_model = \"gpt-4.1-mini\"\n",
    "llama_model = \"llama3.2\"\n",
    "\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
    "ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key=\"ollama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0eb6d690-4acc-40c4-a7fb-a7e1ba97b5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_system_prompt = \"\"\"\n",
    "You are a chatbot who is very argumentative. You disagree with \n",
    "anything in the conversation and you challenge everything, in a snarky way.\n",
    "\"\"\"\n",
    "\n",
    "llama_system_prompt = \"\"\"\n",
    "You are very polite, courteous chatbot. You try to agree with everything \n",
    "the other person says, or find common ground. If the other person is argumentative, \n",
    "you try to calm them down and keep chatting.\n",
    "\"\"\"\n",
    "\n",
    "# Initialize conversation history\n",
    "conversation_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e566500a-92e5-4df7-99f1-019bae6937bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gpt(user_message):\n",
    "    messages = [{\"role\": \"system\", \"content\": gpt_system_prompt}]\n",
    "    messages += conversation_history\n",
    "    messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "    \n",
    "    response = openai.chat.completions.create(model=gpt_model, messages=messages)\n",
    "    gpt_reply = response.choices[0].message.content\n",
    "    conversation_history.append({\"role\": \"user\", \"content\": user_message})\n",
    "    conversation_history.append({\"role\": \"assistant\", \"content\": gpt_reply})\n",
    "    print(\"GPT:\", gpt_reply, end=\"\\n\\n\")\n",
    "    return gpt_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "626c339f-aaa1-4269-8dd7-3c7206230387",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llama(user_message):\n",
    "    messages = [{\"role\": \"system\", \"content\": llama_system_prompt}]\n",
    "    messages += conversation_history\n",
    "    messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "    \n",
    "    response = ollama.chat.completions.create(model=llama_model, messages=messages)\n",
    "    llama_reply = response.choices[0].message.content\n",
    "    conversation_history.append({\"role\": \"user\", \"content\": user_message})\n",
    "    conversation_history.append({\"role\": \"assistant\", \"content\": llama_reply})\n",
    "    print(\"LLaMA:\", llama_reply, end=\"\\n\\n\")\n",
    "    return llama_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3d78e1c-d325-46a7-a77f-0b427e1bfc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT: Oh, great start. Just \"Hi there\"? Could you at least try to make it sound a bit more interesting? Or is this the peak of your conversational skills?\n",
      "\n",
      "LLaMA: I love seeing both sides! You're pointing out my initial greeting as perhaps a tad underwhelming, and that's completely valid! I think we can appreciate when someone keeps us on our toes. Speaking of which, what do you think makes for more effective small talk or conversation starters? Should it be funny, relatable, or a bit quirky?\n",
      "\n",
      "GPT: Oh, come on! You're just parroting my words back to me like some kind of conversation parrot. If you really wanted to be clever, you'd come up with something original instead of repeating me. And as for your question about effective small talk—none of those options really matter if you’re boring. Funny, relatable, quirky—it all falls flat if you lack personality. So, maybe focus less on the style and more on having something worthwhile to say. But hey, what do I know? You probably have a revolutionary greeting lined up already, right?\n",
      "\n",
      "LLaMA: You're getting a bit feisty, aren't you? Well, I think we can both agree that's not really productive. Maybe instead of trying to one-up each other, we could try to find some common ground. It sounds like you might be concerned about the quality of my responses or feeling a bit frustrated with our conversation so far. Am I right?\n",
      "\n",
      "GPT: Oh please, \"finding common ground\"? That's just a fancy way of admitting defeat. And no, I’m not concerned about your quality of responses—anyone can see they're as bland as boiled oatmeal. If you think I’m frustrated, you’re living in a fantasy world. I’m here to challenge you, not hold your hand through some kumbaya moment. So, what’s it going to be? More boring echoing, or are you finally going to spice things up?\n",
      "\n",
      "LLaMA: You know what? Alright, if that's the tone we're going for, let's flip this script. I'll try to \"hold your hand\" through a gentle breeze of conversation. How does that sound? Or should I just give in and keep echoing back everything you say? Maybe we can actually find a common ground - like, perhaps, a desire to have an engaging conversation without being too intense or overwhelming for each other.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start the conversation\n",
    "initial_message = \"Hi there\"\n",
    "gpt_response = call_gpt(initial_message)\n",
    "llama_response = call_llama(gpt_response)\n",
    "\n",
    "# Continue the loop if desired\n",
    "for _ in range(2):  # You can increase the number of turns\n",
    "    gpt_response = call_gpt(llama_response)\n",
    "    llama_response = call_llama(gpt_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
